% 把 Benchmark 集成到 CI Pipeline 中
% liyan
% 2021-07-19

## Benchmark 概览

### 软件为什么要进行基准测试呢？

- If you cannot measure it, you cannot improve it.
  - —   Lord Kelvin
- 性能优化是一个持续改进的过程，如果没有好的措施来看护软件的性能基线，就很容易导致软件系统的性能长期处于不稳定的状态
- 基准测试的目的，就是为软件系统获取一个已知的基线水平。这样，当软件修改变化导致性能发生劣化的时候，我们就可以在第一时间发现问题

::: notes

- 但是，如何对软件系统做好基准测试，是一件非常有挑战的事情！
- 就拿 RePACS 服务来说，要对其进行性能测试时，需要模拟很多种类型的用户请求，可是这在测试场景下是很难构造的。

:::

### 基准测试的分类

按照被测系统规模，可以分为微基准测试与宏基准测试

- 微基准测试主要针对的是软件编码实现层面上的性能基线测试
- 宏基准测试则是针对产品系统级所开展的性能基线测试

::: notes

微基准测试是对代码执行时间的一项测量活动

- 针对较小的代码段运行时间测不准的问题，微基准测试的一种可行方式，就是迭代、累积运行多次后获取的测试时间间隔，然后再平均到每一次的运行时间上，这样就可以减少获取的时间间隔误差对测量结果的影响

宏基准性能测试

- 全系统端到端的性能测试
- 组件 / 服务级的性能测试
- 在产品服务发布之后，人工进行性能测试

:::

### 系统级性能基准测试挑战

1. 全量系统规模大，不易复制
2. 引入多机 Cache 机制，仿真业务性能难
3. 引入安全机制，导致仿真用户难
4. 业务场景多样分布，测试难复制

::: notes

更高效的做法

- 通过软件系统架构分析，将系统级性能基准指标拆分成规模较小的子系统或服务上的性能测试
- 然后再通过小规模的性能基准测试结果组合，分析系统级的关键性能，从而实现使用比较低的成本获取更核心的性能指标的目的

:::

## 微基准测试 Pipeline

### pytest-benchmark

- 引入测试框架

### pytest-benchmark

- 本地集成 Pipeline

::: notes

:::

### gitlab-runner 执行 Pipeline

- 本地调试 pipeline
  - $ gitlab-runner exec shell build-dev-image
- 用 docker 模式
  - $ gitlab-runner exec docker unit-test-and-microbenchmarking
- 使用当前用户在后台运行
  - $ nohup gitlab-runner run 1> runner.log 2>&1 &

### Schedule Pipeline

## 最佳实践

### 用自动化避免重复性工作

- 测试数据准备阶段
- 测试环境准备阶段
- 测试执行阶段
- 测试结果记录阶段

::: notes

测试环境准备阶段

- dev.dockerfile 是目前封装 Pipeline 的基础设施的方式
- docker-compose.yml 封装服务配置

测试执行阶段

- 微基准性能测试直接集成到单元测试阶段，commit 触发
- 宏基准性能测试，定义独立的测试阶段，定时触发
- .gitlab-ci.yml 封装执行逻辑

:::

### 集成面临的挑战

- 执行成本
- 稳定性要求
- 性能结果准确性要求

::: notes

- 性能测试的执行花销是不能忽视的：外部接口都可以 mock

- 需要考虑将性能系统中，软 / 硬件稳定性比较差的依赖项隔离出去

- 避免波动的一些方法：大粒度，重复多次

:::
